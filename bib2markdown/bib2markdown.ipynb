{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BibTeX to Markdown Converter\n",
    "\n",
    "This program converts a BibTeX data file into a formatted paper list in Markdown. BibTeX is widely used for referencing in academic papers, but Markdown is a simpler, more readable format for displaying lists of references on web pages or in documents. By converting BibTeX entries to Markdown, you can easily present bibliographic information in a clean way.\n",
    "\n",
    "Example\n",
    "Given the following BibTeX entry:\n",
    "```bibtex\n",
    "@article{karpathy2015visualizing,\n",
    "  title={Visualizing and understanding recurrent networks},\n",
    "  author={Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li},\n",
    "  journal={arXiv preprint arXiv:1506.02078},\n",
    "  year={2015}\n",
    "}\n",
    "```\n",
    "\n",
    "The program will produce the following Markdown formatted paper list:\n",
    "\n",
    "**Visualizing and understanding recurrent networks**. Karpathy, Andrej, Justin Johnson, and Li Fei-Fei. *arXiv preprint arXiv:1506.02078* (2015).\n",
    "\n",
    "\n",
    "Get an API key from the links below\n",
    "\n",
    "https://www.scraperapi.com/blog/best-google-scholar-apis-proxies/\n",
    "\n",
    "https://serpapi.com/google-scholar-organic-results\n",
    "\n",
    "https://serpdog.io/google-scholar-api/\n",
    "\n",
    "https://www.scaleserp.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# References\\n\\n- **Authorship attribution** by Holmes, David I, 1994\\n- **Combating Misinformation in the Age of LLMs: Opportunities and Challenges** by Canyu Chen and Kai Shu, 2023\\n- **The state of authorship attribution studies: Some problems and solutions** by Rudman, Joseph, 1997\\n- **Machine learning in automated text categorization** by Sebastiani, Fabrizio, 2002\\n- **A survey of modern authorship attribution methods** by Stamatatos, Efstathios, 2009\\n- **Adversarial stylometry: Circumventing authorship recognition to preserve privacy and anonymity** by Brennan, Michael and Afroz, Sadia and Greenstadt, Rachel, 2012\\n- **Authorship verification: a review of recent advances** by Stamatatos, Efstathios, 2016\\n- **A Survey on Authorship Analysis Tasks and Techniques** by Misini, Arta and Kadriu, Arbana and Canhasi, Ercan, No year\\n- **Code authorship attribution: Methods and challenges** by Kalgutkar, Vaibhavi and Kaur, Ratinder and Gonzalez, Hugo and Stakhanova, Natalia and Matyukhina, Alina, 2019\\n- **Automatic detection of machine generated text: A critical survey** by Jawahar, Ganesh and Abdul-Mageed, Muhammad and Lakshmanan, Laks VS, 2020\\n- **Overview of the Cross-Domain Authorship Verification Task at PAN 2021.** by Kestemont, Mike and Manjavacas, Enrique and Markov, Ilia and Bevendorff, Janek and Wiegmann, Matti and Stamatatos, Efstathios and Potthast, Martin and Stein, Benno, 2021\\n- **Developing a benchmark for reducing data bias in authorship attribution** by Murauer, Benjamin and Specht, G{\\\\\"u}nther, 2021\\n- **What does it mean for a language model to preserve privacy?** by Brown, Hannah and Lee, Katherine and Mireshghallah, Fatemehsadat and Shokri, Reza and Tram{\\\\`e}r, Florian, 2022\\n- **Do language models plagiarize?** by Lee, Jooyoung and Le, Thai and Chen, Jinghui and Lee, Dongwon, 2023\\n- **Transferring bert-like transformers’ knowledge for authorship verification** by Manolache, Andrei and Brad, Florin and Burceanu, Elena and Barbalau, Antonio and Ionescu, Radu and Popescu, Marius, 2021\\n- **Roberta: A robustly optimized bert pretraining approach** by Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin, 2019\\n- **Sentence-bert: Sentence embeddings using siamese bert-networks** by Reimers, Nils and Gurevych, Iryna, 2019\\n- **Inference in an authorship problem: A comparative study of discrimination methods applied to the authorship of the disputed Federalist Papers** by Mosteller, Frederick and Wallace, David L, 1963\\n- **The characteristic curves of composition** by Mendenhall, Thomas Corwin, 1887\\n- **On sentence-length as a statistical characteristic of style in prose: With application to two cases of disputed authorship** by Yule, G Udny, 1939\\n- **The statistical study of literary vocabulary** by Yule, C Udny, 1944\\n- **Stylometry** by Binongo, Jose Nilo G, 1996\\n- **Gender, genre, and writing style in formal written texts** by Argamon, Shlomo and Koppel, Moshe and Fine, Jonathan and Shimoni, Anat Rachel, 2003\\n- **Psychological aspects of natural language use: Our words, our selves** by Pennebaker, James W and Mehl, Matthias R and Niederhoffer, Kate G, 2003\\n- **Author identification, idiolect, and linguistic uniqueness** by Coulthard, Malcolm, 2004\\n- **Determining an author\\'s native language by mining a text for errors** by Koppel, Moshe and Schler, Jonathan and Zigdon, Kfir, 2005\\n- **Effects of age and gender on blogging.** by Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James W, 2006\\n- **Authorship verification for short messages using stylometry** by Brocardo, Marcelo Luiz and Traore, Issa and Saad, Sherif and Woungang, Isaac, 2013\\n- **Surveying stylometry techniques and applications** by Neal, Tempestt and Sundararajan, Kalaivani and Fatima, Aneez and Yan, Yiming and Xiang, Yingfei and Woodard, Damon, 2017\\n- **A survey on stylometric text features** by Lagutina, Ksenia and Lagutina, Nadezhda and Boychuk, Elena and Vorontsova, Inna and Shliakhtina, Elena and Belyaeva, Olga and Paramonov, Ilya and Demidov, PG, 2019\\n- **Automatically categorizing written texts by author gender** by Koppel, Moshe and Argamon, Shlomo and Shimoni, Anat Rachel, 2002\\n- **Profile-based authorship analysis** by Dunn, Jonathan and Argamon, Shlomo and Rasooli, Amin and Kumar, Geet, 2016\\n- **Automatically profiling the author of an anonymous text** by Argamon, Shlomo and Koppel, Moshe and Pennebaker, James W and Schler, Jonathan, 2009\\n- **Ad-hoc authorship attribution competition** by Juola, Patrick, 2004\\n- **Effects of age and gender on blogging.** by Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James W, 2006\\n- **Authorship attribution with topic models** by Seroussi, Yanir and Zukerman, Ingrid and Bohnert, Fabian, 2014\\n- **The paradox of corrupt networks: An analysis of organizational crime at Enron** by Aven, Brandy L, 2015\\n- **The enron corpus: A new dataset for email classification research** by Klimt, Bryan and Yang, Yiming, 2004\\n- **Justifying recommendations using distantly-labeled reviews and fine-grained aspects** by Ni, Jianmo and Li, Jiacheng and McAuley, Julian, 2019\\n- **The pushshift reddit dataset** by Baumgartner, Jason and Zannettou, Savvas and Keegan, Brian and Squire, Megan and Blackburn, Jeremy, 2020\\n- **The importance of suppressing domain style in authorship analysis** by Bischoff, Sebastian and Deckers, Niklas and Schliebs, Marcel and Thies, Ben and Hagen, Matthias and Stamatatos, Efstathios and Stein, Benno and Potthast, Martin, 2020\\n- **Overview of pan 2020: Authorship verification, celebrity profiling, profiling fake news spreaders on twitter, and style change detection** by Bevendorff, Janek and Ghanem, Bilal and Giachanou, Anastasia and Kestemont, Mike and Manjavacas, Enrique and Markov, Ilia and Mayerl, Maximilian and Potthast, Martin and Rangel, Francisco and Rosso, Paolo and others, 2020\\n- **TURINGBENCH: A benchmark environment for Turing test in the age of neural text generation** by Uchendu, Adaku and Ma, Zeyu and Le, Thai and Zhang, Rui and Lee, Dongwon, 2021\\n- **On the state of the art in authorship attribution and authorship verification** by Tyo, Jacob and Dhingra, Bhuwan and Lipton, Zachary C, 2022\\n- **Overview of PAN 2022: Authorship Verification, Profiling Irony and Stereotype Spreaders, and Style Change Detection** by Bevendorff, Janek and Chulvi, Berta and Fersini, Elisabetta and Heini, Annina and Kestemont, Mike and Kredens, Krzysztof and Mayerl, Maximilian and Ortega-Bueno, Reynier and P{\\\\k{e}}zik, Piotr and Potthast, Martin and others, 2022\\n- **Creating and detecting fake reviews of online products** by Salminen, Joni and Kandpal, Chandrashekhar and Kamel, Ahmed Mohamed and Jung, Soon-gyo and Jansen, Bernard J, 2022\\n- **Finding deceptive opinion spam by any stretch of the imagination** by Ott, Myle and Choi, Yejin and Cardie, Claire and Hancock, Jeffrey T, 2011\\n- **Defending against neural fake news** by Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin, 2019\\n- **Detecting cross-modal inconsistency to defend against neural fake news** by Tan, Reuben and Plummer, Bryan A and Saenko, Kate, 2020\\n- **SynSciPass: detecting appropriate uses of scientific text generation** by Rosati, Domenic, 2022\\n- **On the generalization of training-based chatgpt detection methods** by Xu, Han and Ren, Jie and He, Pengfei and Zeng, Shenglai and Cui, Yingqian and Liu, Amy and Liu, Hui and Tang, Jiliang, 2023\\n- **M4: Multi-generator, multi-domain, and multi-lingual black-box machine-generated text detection** by Wang, Yuxia and Mansurov, Jonibek and Ivanov, Petar and Su, Jinyan and Shelmanov, Artem and Tsvigun, Akim and Whitehouse, Chenxi and Afzal, Osama Mohammed and Mahmoud, Tarek and Sasaki, Toru and others, 2023\\n- **Evaluating AIGC detectors on code content** by Wang, Jian and Liu, Shangqing and Xie, Xiaofei and Li, Yi, 2023\\n- **Cheat: A large-scale dataset for detecting chatgpt-written abstracts** by Yu, Peipeng and Chen, Jiahan and Feng, Xuan and Xia, Zhihua, 2023\\n- **Ghostbuster: Detecting text ghostwritten by large language models** by Verma, Vivek and Fleisig, Eve and Tomlin, Nicholas and Klein, Dan, 2023\\n- **Gpt-sentinel: Distinguishing human and chatgpt generated content** by Chen, Yutian and Kang, Hao and Zhai, Vivian and Li, Liangze and Singh, Rita and Raj, Bhiksha, 2023\\n- **Mgtbench: Benchmarking machine-generated text detection** by He, Xinlei and Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang, 2023\\n- **MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark** by Macko, Dominik and Moro, Robert and Uchendu, Adaku and Lucas, Jason Samuel and Yamashita, Michiharu and Pikuliak, Mat{\\\\\\'u}{\\\\v{s}} and Srba, Ivan and Le, Thai and Lee, Dongwon and Simko, Jakub and others, 2023\\n- **Cross-domain detection of GPT-2-generated technical text** by Rodriguez, Juan Diego and Hay, Todd and Gros, David and Shamsi, Zain and Srinivasan, Ravi, 2022\\n- **Creating and detecting fake reviews of online products** by Salminen, Joni and Kandpal, Chandrashekhar and Kamel, Ahmed Mohamed and Jung, Soon-gyo and Jansen, Bernard J, 2022\\n- **Mining e-mail content for author identification forensics** by De Vel, Olivier and Anderson, Alison and Corney, Malcolm and Mohay, George, 2001\\n- **Who’s at the keyboard? Authorship attribution in digital evidence investigations** by Chaski, Carole E, 2005\\n- **Quantifying evidence in forensic authorship analysis.** by Grant, Tim, 2007\\n- **Authorship attribution in law enforcement scenarios** by Koppel, Moshe and Schler, Jonathan and Messeri, Eran, 2008\\n- **Ghosts from the high court\\'s past: Evidence from computational linguistics for Dixon ghosting for Mctiernan and rich** by Seroussi, Yanir and Smyth, Russell and Zukerman, Ingrid, 2011\\n- **Plagiarism and authorship analysis: introduction to the special issue** by Stamatatos, Efstathios and Koppel, Moshe, 2011\\n- **Detecting hoaxes, frauds, and deception in writing style online** by Afroz, Sadia and Brennan, Michael and Greenstadt, Rachel, 2012\\n- **Stylometry and immigration: A case study** by Juola, Patrick, 2012\\n- **Authorship attribution for forensic investigation with thousands of authors** by Yang, Min and Chow, Kam-Pui, 2014\\n- **The Rowling case: a proposed standard analytic protocol for authorship questions** by Juola, Patrick, 2015\\n- **Authorship attribution for social media forensics** by Rocha, Anderson and Scheirer, Walter J and Forstall, Christopher W and Cavalcante, Thiago and Theophilo, Antonio and Shen, Bingyu and Carvalho, Ariadne RB and Stamatatos, Efstathios, 2016\\n- **Computational forensic authorship analysis: Promises and pitfalls** by Argamon, Shlomo, 2018\\n- **Forensic authorship analysis of microblogging texts using n-grams and stylometric features** by Belvisi, Nicole Mariah Sharon and Muhammad, Naveed and Alonso-Fernandez, Fernando, 2020\\n- **Text messaging forensics: Txt 4n6: idiolect-free authorship analysis?** by Grant, Tim, 2020\\n- **Large language models can be used to effectively scale spear phishing campaigns** by Hazell, Julian, 2023\\n- **AI model GPT-3 (dis) informs us better than humans** by Spitale, Giovanni and Biller-Andorno, Nikola and Germani, Federico, 2023\\n- **ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing** by Lund, Brady D and Wang, Ting and Mannuru, Nishith Reddy and Nie, Bing and Shimray, Somipam and Wang, Ziang, 2023\\n- **Authorship verification applied to detection of compromised accounts on online social networks: A continuous approach** by Barbon, Sylvio and Igawa, Rodrigo Augusto and Bogaz Zarpel{\\\\~a}o, Bruno, 2017\\n- **Classification for authorship of tweets by comparing logistic regression and naive bayes classifiers** by Aborisade, Opeyemi and Anwar, Mohd, 2018\\n- **Exclusive: FBI document warns conspiracy theories are a new domestic terrorism threat** by Winter, Jana, 2019\\n- **Mining disinformation and fake news: Concepts, methods, and recent advancements** by Shu, Kai and Wang, Suhang and Lee, Dongwon and Liu, Huan, 2020\\n- **Linking user accounts across social media platforms** by Sinnott, Richard and Wang, Zijian, 2021\\n- **Authorship attribution of social media messages** by Theophilo, Antonio and Giot, Romain and Rocha, Anderson, 2021\\n- **Unified and multilingual author profiling for detecting haters** by Schlicht, Ipek Baris and de Paula, Angel Felipe Magnoss{\\\\~a}o, 2021\\n- **Authorship verification applied to detection of compromised accounts on online social networks: A continuous approach** by Barbon, Sylvio and Igawa, Rodrigo Augusto and Bogaz Zarpel{\\\\~a}o, Bruno, 2017\\n- **User identity linkage across online social networks: A review** by Shu, Kai and Wang, Suhang and Tang, Jiliang and Zafarani, Reza and Liu, Huan, 2017\\n- **Support vector machines for spam categorization** by Drucker, Harris and Wu, Donghui and Vapnik, Vladimir N, 1999\\n- **Opinion spam and analysis** by Jindal, Nitin and Liu, Bing, 2008\\n- **The significance of user-defined identifiers in Java source code authorship identification** by Georgia Frantzeskou and Stephen G. MacDonell and Efstathios Stamatatos and Stelios Georgiou and Stefanos Gritzalis, 2021\\n- **Effective identification of source code authors using byte-level information** by Frantzeskou, Georgia and Stamatatos, Efstathios and Gritzalis, Stefanos and Katsikas, Sokratis, 2006\\n- **Plagiarism detection without reference collections** by Meyer zu Eissen, Sven and Stein, Benno and Kulig, Marion, 2007\\n- **Paraphrase plagiarism identification with character-level features** by S{\\\\\\'a}nchez-Vega, Fernando and Villatoro-Tello, Esa{\\\\\\'u} and Montes-y-G{\\\\\\'o}mez, Manuel and Rosso, Paolo and Stamatatos, Efstathios and Villasenor-Pineda, Luis, 2019\\n- **DeepTextMark: Deep Learning based Text Watermarking for Detection of Large Language Model Generated Text** by Munyer, Travis and Zhong, Xin, 2023\\n- **Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense** by Krishna, Kalpesh and Song, Yixiao and Karpinska, Marzena and Wieting, John and Iyyer, Mohit, 2023\\n- **The linguistic sciences and language teaching.** by Halliday, Michael Alexander Kirkwood and others, 1964\\n- **Grammatical word class variation within the British National Corpus sampler** by Rayson, Paul and Wilson, Andrew and Leech, Geoffrey, 2002\\n- **Lying words: Predicting deception from linguistic styles** by Newman, Matthew L and Pennebaker, James W and Berry, Diane S and Richards, Jane M, 2003\\n- **Author identification, idiolect, and linguistic uniqueness** by Coulthard, Malcolm, 2004\\n- **On lying and being lied to: A linguistic analysis of deception in computer-mediated communication** by Hancock, Jeffrey T and Curry, Lauren E and Goorha, Saurabh and Woodworth, Michael, 2007\\n- **The handbook of language variation and change** by Chambers, Jack K and Trudgill, Peter and Schilling-Estes, Natalie, 2013\\n- **The secret life of pronouns. what our words say about us** by Nerbonne, John, 2014\\n- **The development and psychometric properties of LIWC2015** by Pennebaker, James W and Boyd, Ryan L and Jordan, Kayla and Blackburn, Kate, 2015\\n- **Performing multilingual analysis with Linguistic Inquiry and Word Count 2015 (LIWC2015). An equivalence study of four languages** by Dud{\\\\u{a}}u, Diana Paula and Sava, Florin Alin, 2021\\n- **Author identification on the large scale** by Madigan, David and Genkin, Alexander and Lewis, David D and Argamon, Shlomo and Fradkin, Dmitriy and Ye, Li, 2005\\n- **A theory of learning from different domains** by Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman, 2010\\n- **Domain independent authorship attribution without domain adaptation** by Menon, Rohith and Choi, Yejin, 2011\\n- **Learning and transferring mid-level image representations using convolutional neural networks** by Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef, 2014\\n- **Domain adaptation for authorship attribution: Improved structural correspondence learning** by Sapkota, Upendra and Solorio, Thamar and Montes, Manuel and Bethard, Steven, 2016\\n- **Domain-adversarial training of neural networks** by Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\\\\c{c}}ois and Marchand, Mario and Lempitsky, Victor, 2016\\n- **Learning sentence embeddings with auxiliary tasks for cross-domain sentiment classification** by Yu, Jianfei and Jiang, Jing, 2016\\n- **End-to-End Adversarial Memory Network for Cross-domain Sentiment Classification.** by Li, Zheng and Zhang, Yun and Wei, Ying and Wu, Yuxiang and Yang, Qiang, 2017\\n- **What represents “style” in authorship attribution?** by Sundararajan, Kalaivani and Woodard, Damon, 2018\\n- **Masking topic-related information to enhance authorship attribution** by Stamatatos, Efstathios, 2018\\n- **Adversarial category alignment network for cross-domain sentiment classification** by Qu, Xiaoye and Zou, Zhikang and Cheng, Yu and Yang, Yang and Zhou, Pan, 2019\\n- **Masking domain-specific information for cross-domain deception detection** by S{\\\\\\'a}nchez-Junquera, Javier and Villase{\\\\~n}or-Pineda, Luis and Montes-y-G{\\\\\\'o}mez, Manuel and Rosso, Paolo and Stamatatos, Efstathios, 2020\\n- **The topic confusion task: A novel evaluation scenario for authorship attribution** by Altakrori, Malik and Cheung, Jackie Chi Kit and Fung, Benjamin CM, 2021\\n- **Learning universal authorship representations** by Rivera-Soto, Rafael A and Miano, Olivia Elizabeth and Ordonez, Juanita and Chen, Barry Y and Khan, Aleem and Bishop, Marcus and Andrews, Nicholas, 2021\\n- **The importance of suppressing domain style in authorship analysis** by Bischoff, Sebastian and Deckers, Niklas and Schliebs, Marcel and Thies, Ben and Hagen, Matthias and Stamatatos, Efstathios and Stein, Benno and Potthast, Martin, 2020\\n- **Measuring Differentiability: Unmasking Pseudonymous Authors.** by Koppel, Moshe and Schler, Jonathan and Bonchek-Dokow, Elisheva, 2007\\n- **Person identification from text and speech genre samples** by Goldstein, Jade and Winder, Ransom and Sabin, Roberta, 2009\\n- **Bert: Pre-training of deep bidirectional transformers for language understanding** by Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina, 2018\\n- **Cross-domain authorship attribution using pre-trained language models** by Barlas, Georgios and Stamatatos, Efstathios, 2020\\n- **Posnoise: An effective countermeasure against topic biases in authorship analysis** by Halvani, Oren and Graner, Lukas, 2021\\n- **The topic confusion task: A novel evaluation scenario for authorship attribution** by Altakrori, Malik and Cheung, Jackie Chi Kit and Fung, Benjamin CM, 2021\\n- **Adversarial soft prompt tuning for cross-domain sentiment analysis** by Wu, Hui and Shi, Xiaodong, 2022\\n- **Inference in an authorship problem: A comparative study of discrimination methods applied to the authorship of the disputed Federalist Papers** by Mosteller, Frederick and Wallace, David L, 1963\\n- **The Federalist revisited: New directions in authorship attribution** by Holmes, David I and Forsyth, Richard S, 1995\\n- **Computer-based authorship attribution without lexical measures** by Stamatatos, Efstathios and Fakotakis, Nikos and Kokkinakis, Georgios, 2001\\n- **Bayesian multinomial logistic regression for author identification** by Madigan, David and Genkin, Alexander and Lewis, David D and Fradkin, Dmitriy, 2005\\n- **On compression-based text classification** by Marton, Yuval and Wu, Ning and Hellerstein, Lisa, 2005\\n- **A framework for authorship identification of online messages: Writing-style features and classification techniques** by Zheng, Rong and Li, Jiexun and Chen, Hsinchun and Huang, Zan, 2006\\n- **Authorship attribution with thousands of candidate authors** by Koppel, Moshe and Schler, Jonathan and Argamon, Shlomo and Messeri, Eran, 2006\\n- **An algorithm for identifying authors using synonyms** by Clark, Jonathan H and Hannon, Charles J, 2007\\n- **Authorship attribution** by Bozkurt, Ilker Nadi and Baghoglu, Ozgur and Uyar, Erkan, 2007\\n- **Bigrams of syntactic labels for authorship discrimination of short texts** by Hirst, Graeme and Feiguina, Ol’ga, 2007\\n- **Writeprints: A stylometric approach to identity-level identification and similarity detection in cyberspace** by Abbasi, Ahmed and Chen, Hsinchun, 2008\\n- **Authorship Attribution of E-Mail: Comparing Classifiers over a New Corpus for Evaluation.** by Allison, Ben and Guthrie, Louise, 2008\\n- **Author identification: Using text sampling to handle the class imbalance problem** by Stamatatos, Efstathios, 2008\\n- **Automated authorship attribution using advanced signal classification techniques** by Ebrahimpour, Maryam and Putni{\\\\c{n}}{\\\\v{s}}, T{\\\\=a}lis J and Berryman, Matthew J and Allison, Andrew and Ng, Brian W-H and Abbott, Derek, 2013\\n- **Breaking the closed-world assumption in stylometric authorship attribution** by Stolerman, Ariel and Overdorf, Rebekah and Afroz, Sadia and Greenstadt, Rachel, 2014\\n- **Author identification using multi-headed recurrent neural networks** by Bagnall, Douglas, 2015\\n- **Character-level and multi-channel convolutional neural networks for large-scale authorship attribution** by Ruder, Sebastian and Ghaffari, Parsa and Breslin, John G, 2016\\n- **Convolutional neural networks for authorship attribution of short texts** by Shrestha, Prasha and Sierra, Sebastian and Gonz{\\\\\\'a}lez, Fabio A and Montes, Manuel and Rosso, Paolo and Solorio, Thamar, 2017\\n- **Deep learning based authorship identification** by Qian, Chen and He, Tianchang and Zhang, Rao, 2017\\n- **Convolutional neural networks for authorship attribution of short texts** by Shrestha, Prasha and Sierra, Sebastian and Gonz{\\\\\\'a}lez, Fabio A and Montes, Manuel and Rosso, Paolo and Solorio, Thamar, 2017\\n- **An investigation of supervised learning methods for authorship attribution in short hinglish texts using char \\\\& word n-grams** by Sharma, Abhay and Nandan, Ananya and Ralhan, Reetika, 2018\\n- **Syntax encoding with application in authorship attribution** by Zhang, Richong and Hu, Zhiyuan and Guo, Hongyu and Mao, Yongyi, 2018\\n- **Syntax encoding with application in authorship attribution** by Zhang, Richong and Hu, Zhiyuan and Guo, Hongyu and Mao, Yongyi, 2018\\n- **Universal language model fine-tuning for text classification** by Howard, Jeremy and Ruder, Sebastian, 2018\\n- **Topic or style? exploring the most useful features for authorship attribution** by Sari, Yunita and Stevenson, Mark and Vlachos, Andreas, 2018\\n- **What represents “style” in authorship attribution?** by Sundararajan, Kalaivani and Woodard, Damon, 2018\\n- **Authorship attribution for neural text generation** by Uchendu, Adaku and Le, Thai and Shu, Kai and Lee, Dongwon, 2020\\n- **Cross-Domain Authorship Attribution Combining Instance Based and Profile-Based Features.** by Bacciu, Andrea and La Morgia, Massimo and Mei, Alessandro and Nemmi, Eugenio Nerio and Neri, Valerio and Stefa, Julinda, 2019\\n- **Does size matter? Authorship attribution, small samples, big problem** by Eder, Maciej, 2015\\n- **Attributing the Bixby Letter using n-gram tracing** by Grieve, Jack and Clarke, Isobelle and Chiang, Emily and Gideon, Hannah and Heini, Annina and Nini, Andrea and Waibel, Emily, 2019\\n- **Deep Learning based Authorship Identification** by Talati, Arth and Sharma, A and Narayanan, R, 2020\\n- **Exploring the limits of transfer learning with a unified text-to-text transformer** by Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J, 2020\\n- **BertAA: BERT fine-tuning for Authorship Attribution** by Fabien, Ma{\\\\\"e}l and Villatoro-Tello, Esa{\\\\\\'u} and Motlicek, Petr and Parida, Shantipriya, 2020\\n- **Cross-domain authorship attribution using pre-trained language models** by Barlas, Georgios and Stamatatos, Efstathios, 2020\\n- **Siamese networks for large-scale author identification** by Saedi, Chakaveh and Dras, Mark, 2021\\n- **Stylometric authorship attribution of collaborative documents** by Dauber, Edwin and Overdorf, Rebekah and Greenstadt, Rachel, 2017\\n- **PART: Pre-trained Authorship Representation Transformer** by Huertas-Tato, Javier and Huertas-Garcia, Alvaro and Martin, Alejandro and Camacho, David, 2022\\n- **Who could be behind QAnon? Authorship attribution with supervised machine-learning** by Cafiero, Florian and Camps, Jean-Baptiste, 2023\\n- **Authorship verification as a one-class classification problem** by Koppel, Moshe and Schler, Jonathan, 2004\\n- **Measuring Differentiability: Unmasking Pseudonymous Authors.** by Koppel, Moshe and Schler, Jonathan and Bonchek-Dokow, Elisheva, 2007\\n- **The “fundamental problem” of authorship attribution** by Koppel, Moshe and Schler, Jonathan and Argamon, Shlomo and Winter, Yaron, 2012\\n- **Similarity learning for authorship verification in social media** by Boenninghoff, Benedikt and Nickel, Robert M and Zeiler, Steffen and Kolossa, Dorothea, 2019\\n- **Improving author verification based on topic modeling** by Potha, Nektaria and Stamatatos, Efstathios, 2019\\n- **Same author or just same topic? towards content-independent style representations** by Wegmann, Anna and Schraagen, Marijn and Nguyen, Dong, 2022\\n- **Recognizing and Imitating Programmer Style: Adversaries in Program Authorship Attribution.** by Simko, Lucy and Zettlemoyer, Luke and Kohno, Tadayoshi, 2018\\n- **A Girl Has No Name: Automated Authorship Obfuscation using Mutant-X.** by Mahmood, Asad and Ahmad, Faizan and Shafiq, Zubair and Srinivasan, Padmini and Zaffar, Fareed, 2019\\n- **Adversarial Authorship Attribution for Deobfuscation** by Zhai, Wanyue and Rusert, Jonathan and Shafiq, Zubair and Srinivasan, Padmini, 2022\\n- **ALISON: Fast and Effective Stylometric Authorship Obfuscation** by Xing, Eric and Venkatraman, Saranya and Le, Thai and Lee, Dongwon, 2024\\n- **Exploring Semantic Perturbations on Grover** by Kulkarni, Pranav and Ji, Ziqing and Xu, Yan and Neskovic, Marko and Nolan, Kevin, 2023\\n- **Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense** by Krishna, Kalpesh and Song, Yixiao and Karpinska, Marzena and Wieting, John and Iyyer, Mohit, 2024\\n- **How effectively can machines defend against machine-generated fake news? an empirical study** by Bhat, Meghana Moorthy and Parthasarathy, Srinivasan, 2020\\n- **Evade ChatGPT detectors via a single space** by Cai, Shuyang and Cui, Wanyun, 2023\\n- **Authorship obfuscation in multilingual machine-generated text detection** by Macko, Dominik and Moro, Robert and Uchendu, Adaku and Srba, Ivan and Lucas, Jason Samuel and Yamashita, Michiharu and Tripto, Nafis Irtiza and Lee, Dongwon and Simko, Jakub and Bielikova, Maria, 2024\\n- **Robustness analysis of grover for machine-generated news detection** by Gagiano, Rinaldo and Kim, Maria Myung-Hee and Zhang, Xiuzhen Jenny and Biggs, Jennifer, 2021\\n- **How reliable are ai-generated-text detectors? an assessment framework using evasive soft prompts** by Kumarage, Tharindu and Sheth, Paras and Moraffah, Raha and Garland, Joshua and Liu, Huan, 2023\\n- **Large language models can be guided to evade ai-generated text detection** by Lu, Ning and Liu, Shengcai and He, Rui and Wang, Qi and Ong, Yew-Soon and Tang, Ke, 2023\\n- **Efficient Black-Box Adversarial Attacks on Neural Text Detectors** by Fishchuk, Vitalii and Braun, Daniel, 2023\\n- **Convolutional neural networks for authorship attribution of short texts** by Shrestha, Prasha and Sierra, Sebastian and Gonz{\\\\\\'a}lez, Fabio A and Montes, Manuel and Rosso, Paolo and Solorio, Thamar, 2017\\n- **Learning invariant representations of social media users** by Andrews, Nicholas and Bishop, Marcus, 2019\\n- **Explainable authorship verification in social media via attention-based similarity learning** by Boenninghoff, Benedikt and Hessler, Steffen and Kolossa, Dorothea and Nickel, Robert M, 2019\\n- **A unified approach to interpreting model predictions** by Lundberg, Scott M and Lee, Su-In, 2017\\n- **Detecting and understanding textual deepfakes in online reviews** by Kowalczyk, Peter and R{\\\\\"o}der, Marco and D{\\\\\"u}rr, Alexander and Thiesse, Fr{\\\\\\'e}d{\\\\\\'e}ric, 2022\\n- **Allennlp interpret: A framework for explaining predictions of nlp models** by Wallace, Eric and Tuyls, Jens and Wang, Junlin and Subramanian, Sanjay and Gardner, Matt and Singh, Sameer, 2019\\n- **Lstmvis: A tool for visual analysis of hidden state dynamics in recurrent neural networks** by Strobelt, Hendrik and Gehrmann, Sebastian and Pfister, Hanspeter and Rush, Alexander M, 2017\\n- **e-snli: Natural language inference with natural language explanations** by Camburu, Oana-Maria and Rockt{\\\\\"a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil, 2018\\n- **Explain yourself! leveraging language models for commonsense reasoning** by Rajani, Nazneen Fatema and McCann, Bryan and Xiong, Caiming and Socher, Richard, 2019\\n- **Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead** by Rudin, Cynthia, 2019\\n- **A survey of the state of explainable AI for natural language processing** by Danilevsky, Marina and Qian, Kun and Aharonov, Ranit and Katsis, Yannis and Kawas, Ban and Sen, Prithviraj, 2020\\n- **Tx-ray: Quantifying and explaining model-knowledge transfer in (un-) supervised NLP** by Rethmeier, Nils and Saxena, Vageesh Kumar and Augenstein, Isabelle, 2020\\n- **Rhetorical structure theory: A framework for the analysis of texts** by Mann, William C and Thompson, Sandra A, 1987\\n- **Rhetorical structure theory: Toward a functional theory of text organization** by Mann, William C and Thompson, Sandra A, 1988\\n- **Building a large annotated corpus of English: The Penn Treebank** by Marcus, Mitchell and Santorini, Beatrice and Marcinkiewicz, Mary Ann, 1993\\n- **Building a discourse-tagged corpus in the framework of rhetorical structure theory** by Carlson, Lynn and Marcu, Daniel and Okurowski, Mary Ellen, 2003\\n- **Text-level discourse parsing with rich linguistic features** by Feng, Vanessa Wei and Hirst, Graeme, 2012\\n- **HILDA: A discourse parser using support vector machine classification** by Hernault, Hugo and Prendinger, Helmut and du Verle, David A and Ishizuka, Mitsuru, 2010\\n- **Representation learning for text-level discourse parsing** by Ji, Yangfeng and Eisenstein, Jacob, 2014\\n- **Recursive deep models for discourse parsing** by Li, Jiwei and Li, Rumeng and Hovy, Eduard, 2014\\n- **A rule based approach to discourse parsing** by Polanyi, Livia and Culy, Chris and Van Den Berg, Martin and Thione, Gian Lorenzo and Ahn, David, 2004\\n- **Fast rhetorical structure theory discourse parsing** by Heilman, Michael and Sagae, Kenji, 2015\\n- **Discourse Parsing with Attention-based Hierarchical Neural Networks.** by Li, Qi and Li, Tianshi and Chang, Baobao, 2016\\n- **On the relevance of syntactic and discourse features for author profiling and identification** by Wanner, Leo and others, 2017\\n- **How much progress have we made on RST discourse parsing? A replication study of recent results on the RST-DT** by Morey, Mathieu and Muller, Philippe and Asher, Nicholas, 2017\\n- **A two-stage parsing method for text-level discourse analysis** by Wang, Yizhong and Li, Sujian and Wang, Houfeng, 2017\\n- **Using and comparing Rhetorical Structure Theory parsers with rst-workbench** by Neumann, Arne, 2021\\n- **A survey of discourse parsing** by Li, Jiaqi and Liu, Ming and Qin, Bing and Liu, Ting, 2022\\n- **Universal language model fine-tuning for text classification** by Howard, Jeremy and Ruder, Sebastian, 2018\\n- **Detecting Fake Content with Relative Entropy Scoring.** by Lavergne, Thomas and Urvoy, Tanguy and Yvon, Fran{\\\\c{c}}ois, 2008\\n- **Realtoxicityprompts: Evaluating neural toxic degeneration in language models** by Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A, 2020\\n- **All that\\'s\\' human\\'is not gold: Evaluating human evaluation of generated text** by Clark, Elizabeth and August, Tal and Serrano, Sofia and Haduong, Nikita and Gururangan, Suchin and Smith, Noah A, 2021\\n- **On pushing DeepFake Tweet Detection capabilities to the limits** by Gambini, Margherita and Fagni, Tiziano and Falchi, Fabrizio and Tesconi, Maurizio, 2022\\n- **Deepfake Text Detection: Limitations and Opportunities** by Pu, Jiameng and Sarwar, Zain and Abdullah, Sifat Muhammad and Rehman, Abdullah and Kim, Yoonjin and Bhattacharya, Parantapa and Javed, Mobin and Viswanath, Bimal, 2022\\n- **Synthetic Text Detection: Systemic Literature Review** by Guerrero, Jesus and Alsmadi, Izzat, 2022\\n- **Detecting computer-generated disinformation** by Stiff, Harald and Johansson, Fredrik, 2022\\n- **Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers** by Gao, Catherine A and Howard, Frederick M and Markov, Nikolay S and Dyer, Emma C and Ramesh, Siddhi and Luo, Yuan and Pearson, Alexander T, 2022\\n- **Detectgpt: Zero-shot machine-generated text detection using probability curvature** by Mitchell, Eric and Lee, Yoonho and Khazatsky, Alexander and Manning, Christopher D and Finn, Chelsea, 2023\\n- **Deepfake text detection: Limitations and opportunities** by Pu, Jiameng and Sarwar, Zain and Abdullah, Sifat Muhammad and Rehman, Abdullah and Kim, Yoonjin and Bhattacharya, Parantapa and Javed, Mobin and Viswanath, Bimal, 2023\\n- **DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text** by Su, Jinyan and Zhuo, Terry Yue and Wang, Di and Nakov, Preslav, 2023\\n- **On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing** by Zeyan Liu and Zijun Yao and Fengjun Li and Bo Luo, 2024\\n- **Can ai-generated text be reliably detected?** by Sadasivan, Vinu Sankar and Kumar, Aounon and Balasubramanian, Sriram and Wang, Wenxiao and Feizi, Soheil, 2023\\n- **The science of detecting llm-generated texts** by Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia, 2023\\n- **Generating Phishing Attacks using ChatGPT** by Roy, Sayak Saha and Naragam, Krishna Vamsi and Nilizadeh, Shirin, 2023\\n- **Jailbreaking chatgpt via prompt engineering: An empirical study** by Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Liu, Yang, 2023\\n- **Social engineering with ChatGPT** by Grbic, Dijana Vukovic and Dujlovic, Igor, 2023\\n- **Bot or human? detecting chatgpt imposters with a single question** by Wang, Hong and Luo, Xuan and Wang, Weizhi and Yan, Xifeng, 2023\\n- **Smaller Language Models are Better Black-box Machine-Generated Text Detectors** by Mireshghallah, Fatemehsadat and Mattern, Justus and Gao, Sicun and Shokri, Reza and Berg-Kirkpatrick, Taylor, 2023\\n- **Computer-generated text detection using machine learning: A systematic review** by Beresneva, Daria, 2016\\n- **Gltr: Statistical detection and visualization of generated text** by Gehrmann, Sebastian and Strobelt, Hendrik and Rush, Alexander M, 2019\\n- **Findings of the the ruatd shared task 2022 on artificial text detection in russian** by Shamardina, Tatiana and Mikhailov, Vladislav and Chernianskii, Daniil and Fenogenova, Alena and Saidov, Marat and Valeeva, Anastasiya and Shavrina, Tatiana and Smurov, Ivan and Tutubalina, Elena and Artemova, Ekaterina, 2022\\n- **Automatic detection of Chinese generated essayss based on pre-trained BERT** by Chen, Xingyuan and Jin, Peng and Jing, Siyuan and Xie, Chunming, 2022\\n- **Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations** by Josh A. Goldstein and Girish Sastry and Micah Musser and Renee DiResta and Matthew Gentzel and Katerina Sedova, 2023\\n- **Lstmvis: A tool for visual analysis of hidden state dynamics in recurrent neural networks** by Strobelt, Hendrik and Gehrmann, Sebastian and Pfister, Hanspeter and Rush, Alexander M, 2017\\n- **Attention is all you need** by Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\\\L}ukasz and Polosukhin, Illia, 2017\\n- **A survey of large language models** by Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others, 2023\\n- **Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model** by Deng, Zhijie and Gao, Hongcheng and Miao, Yibo and Zhang, Hao, 2023\\n- **ChatGPT Generated Text Detection** by Shijaku, Rexhep and Canhasi, Ercan, 2023\\n- **DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text** by Yang, Xianjun and Cheng, Wei and Petzold, Linda and Wang, William Yang and Chen, Haifeng, 2023\\n- **Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model** by Deng, Zhijie and Gao, Hongcheng and Miao, Yibo and Zhang, Hao, 2023\\n- **GPT detectors are biased against non-native English writers** by Liang, Weixin and Yuksekgonul, Mert and Mao, Yining and Wu, Eric and Zou, James, 2023\\n- **Automated identification of social media bots using deepfake text detection** by Saravani, Sina Mahdipour and Ray, Indrajit and Ray, Indrakshi, 2021\\n- **REVERSE TURING TEST IN THE AGE OF DEEPFAKE TEXTS** by Uchendu, Adaku, 2023\\n- **Feature-based detection of automated language models: tackling GPT-2, GPT-3 and Grover** by Fr{\\\\\"o}hling, Leon and Zubiaga, Arkaitz, 2021\\n- **Human behavior and the principle of least effort: An introduction to human ecology** by Zipf, George Kingsley, 2016\\n- **The curious case of neural text degeneration** by Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin, 2019\\n- **Identifying computer-generated text using statistical analysis** by Nguyen-Son, Hoang-Quoc and Tieu, Ngoc-Dung T and Nguyen, Huy H and Yamagishi, Junichi and Zen, Isao Echi, 2017\\n- **Do massively pretrained language models make better storytellers?** by See, Abigail and Pappu, Aneesh and Saxena, Rohun and Yerukola, Akhila and Manning, Christopher D, 2019\\n- **How effectively can machines defend against machine-generated fake news? an empirical study** by Bhat, Meghana Moorthy and Parthasarathy, Srinivasan, 2020\\n- **Automatic Detection of Hybrid Human-Machine Text Boundaries** by Cutler, Joseph and Dugan, Liam and Havaldar, Shreya and Stein, Adam, 2021\\n- **Don\\'t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization** by Narayan, Shashi and Cohen, Shay B and Lapata, Mirella, 2018\\n- **A discourse-aware attention model for abstractive summarization of long documents** by Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli, 2018\\n- **Language models are unsupervised multitask learners** by Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others, 2019\\n- **The Pile: An 800GB Dataset of Diverse Text for Language Modeling** by Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others, 2020\\n- **{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}** by Wang, Ben and Komatsuzaki, Aran, 2021\\n- **Llama: Open and efficient foundation language models** by Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\\\\\'e}e and Rozi{\\\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others, 2023\\n- **Release strategies and the social impacts of language models** by Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Krueger, Gretchen and Kim, Jong Wook and Kreps, Sarah and others, 2019\\n- **Can Large Language Models Identify Authorship?** by Huang, Baixiang and Chen, Canyu and Shu, Kai, 2024\\n- **Language models are few-shot learners** by Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others, 2020\\n- **Large language models are zero-shot reasoners** by Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke, 2022\\n- **The science of detecting llm-generated texts** by Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia, 2023\\n- **Neural Authorship Attribution: Stylometric Analysis on Large Language Models** by Kumarage, Tharindu and Liu, Huan, 2023\\n- **RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors** by Dugan, Liam and Hwang, Alyssa and Trhlik, Filip and Ludan, Josh Magnus and Zhu, Andrew and Xu, Hainiu and Ippolito, Daphne and Callison-Burch, Chris, 2024\\n- **A survey on detection of llms-generated content** by Yang, Xianjun and Pan, Liangming and Zhao, Xuandong and Chen, Haifeng and Petzold, Linda and Wang, William Yang and Cheng, Wei, 2023\\n- **Learning Interpretable Style Embeddings via Prompting LLMs** by Patel, Ajay and Rao, Delip and Callison-Burch, Chris, 2023\\n- **A survey on llm-gernerated text detection: Necessity, methods, and future directions** by Wu, Junchao and Yang, Shu and Zhan, Runzhe and Yuan, Yulin and Wong, Derek F and Chao, Lidia S, 2023\\n- **A watermark for large language models** by Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom, 2023\\n- **Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense** by Krishna, Kalpesh and Song, Yixiao and Karpinska, Marzena and Wieting, John and Iyyer, Mohit, 2024\\n- **Natural language watermarking: Design, analysis, and a proof-of-concept implementation** by Atallah, Mikhail J and Raskin, Victor and Crogan, Michael and Hempelmann, Christian and Kerschbaum, Florian and Mohamed, Dina and Naik, Sanket, 2001\\n- **Natural language watermarking** by Topkara, Mercan and Taskiran, Cuneyt M and Delp III, Edward J, 2005\\n- **A review of digital watermarking techniques for text documents** by Jalil, Zunera and Mirza, Anwar M, 2009\\n- **Adversarial watermarking transformer: Towards tracing text provenance with data hiding** by Abdelnabi, Sahar and Fritz, Mario, 2021\\n- **Tracing text provenance via context-aware lexical substitution** by Yang, Xi and Zhang, Jie and Chen, Kejiang and Zhang, Weiming and Ma, Zehua and Wang, Feng and Yu, Nenghai, 2022\\n- **Zipf’s word frequency law in natural language: A critical review and future directions** by Piantadosi, Steven T, 2014\\n- **Automatic detection of generated text is easiest when humans are fooled** by Ippolito, Daphne and Duckworth, Daniel and Callison-Burch, Chris and Eck, Douglas, 2019\\n- **Unsupervised and distributional detection of machine-generated text** by Gall{\\\\\\'e}, Matthias and Rozen, Jos and Kruszewski, Germ{\\\\\\'a}n and Elsahar, Hady, 2021\\n- **Supervised contrastive learning** by Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip, 2020\\n- **Explaining and harnessing adversarial examples** by Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian, 2014\\n- **Improved certified defenses against data poisoning with (deterministic) finite aggregation** by Wang, Wenxiao and Levine, Alexander J and Feizi, Soheil, 2022\\n- **Automatic detection of machine generated text: A critical survey** by Jawahar, Ganesh and Abdul-Mageed, Muhammad and Lakshmanan, Laks VS, 2020\\n- **TweepFake: About detecting deepfake tweets** by Fagni, Tiziano and Falchi, Fabrizio and Gambini, Margherita and Martella, Antonio and Tesconi, Maurizio, 2021\\n- **Neural deepfake detection with factual structure of text** by Zhong, Wanjun and Tang, Duyu and Xu, Zenan and Wang, Ruize and Duan, Nan and Zhou, Ming and Wang, Jiahai and Yin, Jian, 2020\\n- **Real or fake text?: Investigating human ability to detect boundaries between human-written and machine-generated text** by Dugan, Liam and Ippolito, Daphne and Kirubarajan, Arun and Shi, Sherry and Callison-Burch, Chris, 2023\\n- **ChatGPT: more than a “weapon of mass deception” ethical challenges and responses from the human-centered artificial intelligence (HCAI) perspective** by Sison, Alejo Jose G and Daza, Marco Tulio and Gozalo-Brizuela, Roberto and Garrido-Merch{\\\\\\'a}n, Eduardo C, 2023\\n- **Best practices for the human evaluation of automatically generated text** by Van Der Lee, Chris and Gatt, Albert and Van Miltenburg, Emiel and Wubben, Sander and Krahmer, Emiel, 2019\\n- **How close is chatgpt to human experts? comparison corpus, evaluation, and detection** by Guo, Biyang and Zhang, Xin and Wang, Ziyuan and Jiang, Minqi and Nie, Jinran and Ding, Yuxuan and Yue, Jianwei and Wu, Yupeng, 2023\\n- **Hc3 plus: A semantic-invariant human chatgpt comparison corpus** by Su, Zhenpeng and Wu, Xing and Zhou, Wei and Ma, Guangyuan and Hu, Songlin, 2023\\n- **ELI5: Long form question answering** by Fan, Angela and Jernite, Yacine and Perez, Ethan and Grangier, David and Weston, Jason and Auli, Michael, 2019\\n- **Fake news detection and fact verification using knowledge graphs and machine learning** by Shakeel, Danish and Jain, Nitin, 2021\\n- **The limitations of stylometry for detecting machine-generated fake news** by Schuster, Tal and Schuster, Roei and Shah, Darsh J and Barzilay, Regina, 2020\\n- **Llmdet: A third party large language models generated text detection tool** by Wu, Kangxi and Pang, Liang and Shen, Huawei and Cheng, Xueqi and Chua, Tat-Seng, 2023\\n- **Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text** by Hans, Abhimanyu and Schwarzschild, Avi and Cherepanova, Valeriia and Kazemi, Hamid and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom, 2024\\n- **Fast-detectgpt: Efficient zero-shot detection of machine-generated text via conditional probability curvature** by Bao, Guangsheng and Zhao, Yanbin and Teng, Zhiyang and Yang, Linyi and Zhang, Yue, 2023\\n- **Radar: Robust ai-text detection via adversarial learning** by Hu, Xiaomeng and Chen, Pin-Yu and Ho, Tsung-Yi, 2023\\n- **Gltr: Statistical detection and visualization of generated text** by Gehrmann, Sebastian and Strobelt, Hendrik and Rush, Alexander M, 2019\\n- **Conda: Contrastive domain adaptation for ai-generated text detection** by Bhattacharjee, Amrita and Kumarage, Tharindu and Moraffah, Raha and Liu, Huan, 2023\\n- **On the zero-shot generalization of machine-generated text detectors** by Pu, Xiao and Zhang, Jingyu and Han, Xiaochuang and Tsvetkov, Yulia and He, Tianxing, 2023\\n- **G3Detector: General GPT-generated text detector** by Zhan, Haolan and He, Xuanli and Xu, Qiongkai and Wu, Yuxiang and Stenetorp, Pontus, 2023\\n- **GPTZero: Towards detection of AI-generated text using zero-shot and supervised methods** by Tian, Edward and Cui, Alexander, 2023\\n- **GPTZero: Towards detection of AI-generated text using zero-shot and supervised methods** by Heini, A., Pezik, P. and Kredens, K., 2021\\n- **OpenWebText Corpus** by Aaron Gokaslan and Vanya Cohen, 2019\\n- **Smaller language models are better black-box machine-generated text detectors** by Mireshghallah, Niloofar and Mattern, Justus and Gao, Sicun and Shokri, Reza and Berg-Kirkpatrick, Taylor, 2023\\n- **On the possibilities of ai-generated text detection** by Chakraborty, Souradip and Bedi, Amrit Singh and Zhu, Sicheng and An, Bang and Manocha, Dinesh and Huang, Furong, 2023\\n- **Natural language watermarking via morphosyntactic alterations** by Meral, Hasan Mesut and Sankur, B{\\\\\"u}lent and {\\\\\"O}zsoy, A Sumru and G{\\\\\"u}ng{\\\\\"o}r, Tunga and Sevin{\\\\c{c}}, Emre, 2009\\n- **Semstamp: A semantic watermark with paraphrastic robustness for text generation** by Hou, Abe Bohan and Zhang, Jingyu and He, Tianxing and Wang, Yichen and Chuang, Yung-Sung and Wang, Hongwei and Shen, Lingfeng and Van Durme, Benjamin and Khashabi, Daniel and Tsvetkov, Yulia, 2023\\n- **Dipmark: A stealthy, efficient and resilient watermark for large language models** by Wu, Yihan and Hu, Zhengmian and Zhang, Hongyang and Huang, Heng, 2023\\n- **Provable robust watermarking for ai-generated text** by Zhao, Xuandong and Ananth, Prabhanjan and Li, Lei and Wang, Yu-Xiang, 2023\\n- **Red teaming language model detectors with language models** by Shi, Zhouxing and Wang, Yihan and Yin, Fan and Chen, Xiangning and Chang, Kai-Wei and Hsieh, Cho-Jui, 2024\\n- **Paraphrase detection: Human vs. machine content** by Becker, Jonas and Wahle, Jan Philip and Ruas, Terry and Gipp, Bela, 2023\\n- **Detectllm: Leveraging log rank information for zero-shot detection of machine-generated text** by Su, Jinyan and Zhuo, Terry Yue and Wang, Di and Nakov, Preslav, 2023\\n- **Fast-detectgpt: Efficient zero-shot detection of machine-generated text via conditional probability curvature** by Bao, Guangsheng and Zhao, Yanbin and Teng, Zhiyang and Yang, Linyi and Zhang, Yue, 2023\\n- **Gpt-who: An information density-based machine-generated text detector** by Venkatraman, Saranya and Uchendu, Adaku and Lee, Dongwon, 2023\\n- **Cross-domain detection of GPT-2-generated technical text** by Rodriguez, Juan Diego and Hay, Todd and Gros, David and Shamsi, Zain and Srinivasan, Ravi, 2022\\n- **Counter Turing Test CT\\\\^{} 2: AI-Generated Text Detection is Not as Easy as You May Think--Introducing AI Detectability Index** by Chakraborty, Megha and Tonmoy, SM and Zaman, SM and Sharma, Krish and Barman, Niyar R and Gupta, Chandan and Gautam, Shreya and Kumar, Tanay and Jain, Vinija and Chadha, Aman and others, 2023\\n- **Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\\\\%* ChatGPT Quality** by Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P., 2023\\n- **Bag of tricks for efficient text classification** by Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas, 2016\\n- **MAGE: Machine-generated Text Detection in the Wild** by Yafu Li and Qintong Li and Leyang Cui and Wei Bi and Zhilin Wang and Longyue Wang and Linyi Yang and Shuming Shi and Yue Zhang, 2024\\n- **Origin tracing and detecting of llms** by Li, Linyang and Wang, Pengyu and Ren, Ke and Sun, Tianxiang and Qiu, Xipeng, 2023\\n- **LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?** by Zhang, Qihui and Gao, Chujie and Chen, Dongping and Huang, Yue and Huang, Yixin and Sun, Zhenyang and Zhang, Shilin and Li, Weiye and Fu, Zhengyan and Wan, Yao and others, 2024\\n- **Through the looking glass: Learning to attribute synthetic text generated by language models** by Munir, Shaoor and Batool, Brishna and Shafiq, Zubair and Srinivasan, Padmini and Zaffar, Fareed, 2021\\n- **Dna-gpt: Divergent n-gram analysis for training-free detection of gpt-generated text** by Yang, Xianjun and Cheng, Wei and Wu, Yue and Petzold, Linda and Wang, William Yang and Chen, Haifeng, 2023\\n- **Long-form analogies generated by chatGPT lack human-like psycholinguistic properties** by Seals, SM and Shalin, Valerie L, 2023\\n- **Self-consuming generative models go mad** by Alemohammad, Sina and Casco-Rodriguez, Josue and Luzi, Lorenzo and Humayun, Ahmed Imtiaz and Babaei, Hossein and LeJeune, Daniel and Siahkoohi, Ali and Baraniuk, Richard G, 2023\\n- **Machine-made media: Monitoring the mobilization of machine-generated articles on misinformation and mainstream news websites** by Hanley, Hans WA and Durumeric, Zakir, 2024\\n- **Machine-generated text: A comprehensive survey of threat models and detection methods** by Crothers, Evan and Japkowicz, Nathalie and Viktor, Herna L, 2023\\n- **On the detectability of chatgpt content: benchmarking, methodology, and evaluation through the lens of academic writing** by Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo, 2023\\n- **ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models** by Liu, Yikang and Zhang, Ziyin and Zhang, Wanyang and Yue, Shisen and Zhao, Xiaojing and Cheng, Xinyuan and Zhang, Yiwen and Hu, Hai, 2023\\n- **Distinguishing Fact from Fiction: A Benchmark Dataset for Identifying Machine-Generated Scientific Papers in the LLM Era.** by Mosca, Edoardo and Abdalla, Mohamed Hesham Ibrahim and Basso, Paolo and Musumeci, Margherita and Groh, Georg, 2023\\n- **Overview of autextification at iberlef 2023: Detection and attribution of machine-generated text in multiple domains** by Sarvazyan, Areg Mikael and Gonz{\\\\\\'a}lez, Jos{\\\\\\'e} {\\\\\\'A}ngel and Franco-Salvador, Marc and Rangel, Francisco and Chulvi, Berta and Rosso, Paolo, 2023\\n- **On the Generalization of Training-based ChatGPT Detection Methods** by Han Xu and Jie Ren and Pengfei He and Shenglai Zeng and Yingqian Cui and Amy Liu and Hui Liu and Jiliang Tang, 2023\\n- **M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection** by Wang, Yuxia and Mansurov, Jonibek and Ivanov, Petar and Su, Jinyan and Shelmanov, Artem and Tsvigun, Akim and Afzal, Osama Mohanned and Mahmoud, Tarek and Puccetti, Giovanni and Arnold, Thomas and others, 2024\\n- **Few-Shot Detection of Machine-Generated Text using Style Representations** by Soto, Rafael Rivera and Koch, Kailin and Khan, Aleem and Chen, Barry and Bishop, Marcus and Andrews, Nicholas, 2024\\n- **HANSEN: human and AI spoken text benchmark for authorship analysis** by Tripto, Nafis Irtiza and Uchendu, Adaku and Le, Thai and Setzu, Mattia and Giannotti, Fosca and Lee, Dongwon, 2023\\n- **A survey on llm-gernerated text detection: Necessity, methods, and future directions** by Wu, Junchao and Yang, Shu and Zhan, Runzhe and Yuan, Yulin and Wong, Derek F and Chao, Lidia S, 2023\\n- **Token prediction as implicit classification to identify LLM-generated text** by Chen, Yutian and Kang, Hao and Zhai, Vivian and Li, Liangze and Singh, Rita and Raj, Bhiksha, 2023\\n- **Automatic Authorship Analysis in Human-AI Collaborative Writing** by Richburg, Aquia and Bao, Calvin and Carpuat, Marine, 2024\\n- **Effect of scale on catastrophic forgetting in neural networks** by Ramasesh, Vinay Venkatesh and Lewkowycz, Aitor and Dyer, Ethan, 2021\\n- **Retrieval-augmented generation for knowledge-intensive nlp tasks** by Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\\\\\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\\\\\"a}schel, Tim and others, 2020\\n- **A survey on data selection for language models** by Albalak, Alon and Elazar, Yanai and Xie, Sang Michael and Longpre, Shayne and Lambert, Nathan and Wang, Xinyi and Muennighoff, Niklas and Hou, Bairu and Pan, Liangming and Jeong, Haewon and others, 2024\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.serpdog.io/google-scholar-api\n",
    "def get_paper_link(title, authors):\n",
    "    api_key = 'API'  # Replace with your Serpdog API key\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"q\": f\"{title} {authors}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\"https://api.serpdog.io/scholar\", params=params)\n",
    "\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"scholar_results\", [])\n",
    "        if results:\n",
    "            # Assuming the first result is the most relevant one\n",
    "            resource_link = results[0].get(\"resources\", [])\n",
    "            if resource_link:\n",
    "                return resource_link[0].get(\"link\", \"No link found\")\n",
    "            else:\n",
    "                return results[0].get(\"title_link\", \"No link found\")\n",
    "        else:\n",
    "            return \"No results found\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "# for paper in papers[:3]:\n",
    "#     title = paper.get('title', 'No Title').strip('{}').replace('\\n', ' ')\n",
    "#     authors = format_authors(paper.get('author', 'No Author'))\n",
    "#     venue = paper.get('booktitle', paper.get('journal', 'No venue'))\n",
    "#     year = paper.get('year', 'No Year')\n",
    "#     link = get_paper_link(title, authors)\n",
    "#     print(f\"{title} {authors}. link: {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Index: 0, title: Fake news detection and fact verification using knowledge graphs and machine learning. link: https://www.researchgate.net/profile/Danish-Shakeel-2/publication/348931042_Fake_news_detection_and_fact_verification_using_knowledge_graphs_and_machine_learning/links/6017de6892851c2d4d0aac7f/Fake-news-detection-and-fact-verification-using-knowledge-graphs-and-machine-learning.pdf\n",
      "<Response [200]>\n",
      "Index: 1, title: The limitations of stylometry for detecting machine-generated fake news. link: https://direct.mit.edu/coli/article-abstract/46/2/499/93369\n",
      "<Response [200]>\n",
      "Index: 2, title: Llmdet: A third party large language models generated text detection tool. link: https://arxiv.org/abs/2305.15004\n",
      "<Response [200]>\n",
      "Index: 3, title: Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text. link: https://arxiv.org/abs/2401.12070\n",
      "<Response [200]>\n",
      "Index: 4, title: Fast-detectgpt: Efficient zero-shot detection of machine-generated text via conditional probability curvature. link: https://arxiv.org/abs/2310.05130\n",
      "<Response [200]>\n",
      "Index: 5, title: Radar: Robust ai-text detection via adversarial learning. link: https://proceedings.neurips.cc/paper_files/paper/2023/hash/30e15e5941ae0cdab7ef58cc8d59a4ca-Abstract-Conference.html\n",
      "<Response [200]>\n",
      "Index: 6, title: Gltr: Statistical detection and visualization of generated text. link: https://arxiv.org/abs/1906.04043\n",
      "<Response [200]>\n",
      "Index: 7, title: Conda: Contrastive domain adaptation for ai-generated text detection. link: https://arxiv.org/abs/2309.03992\n",
      "<Response [200]>\n",
      "Index: 8, title: On the zero-shot generalization of machine-generated text detectors. link: https://arxiv.org/abs/2310.05165\n",
      "<Response [200]>\n",
      "Index: 9, title: G3Detector: General GPT-generated text detector. link: https://arxiv.org/abs/2305.12680\n",
      "<Response [200]>\n",
      "Index: 10, title: GPTZero: Towards detection of AI-generated text using zero-shot and supervised methods. link: No results found\n",
      "<Response [200]>\n",
      "Index: 11, title: GPTZero: Towards detection of AI-generated text using zero-shot and supervised methods. link: No results found\n",
      "<Response [200]>\n",
      "Index: 12, title: OpenWebText Corpus. link: No results found\n",
      "<Response [200]>\n",
      "Index: 13, title: Smaller language models are better black-box machine-generated text detectors. link: https://arxiv.org/abs/2305.09859\n",
      "<Response [200]>\n",
      "Index: 14, title: On the possibilities of ai-generated text detection. link: https://arxiv.org/abs/2304.04736\n",
      "<Response [200]>\n",
      "Index: 15, title: Natural language watermarking via morphosyntactic alterations. link: https://www.sciencedirect.com/science/article/pii/S0885230808000284\n",
      "<Response [200]>\n",
      "Index: 16, title: Semstamp: A semantic watermark with paraphrastic robustness for text generation. link: https://arxiv.org/abs/2310.03991\n",
      "<Response [200]>\n",
      "Index: 17, title: Dipmark: A stealthy, efficient and resilient watermark for large language models. link: https://arxiv.org/abs/2310.07710\n",
      "<Response [200]>\n",
      "Index: 18, title: Provable robust watermarking for ai-generated text. link: https://arxiv.org/abs/2306.17439\n",
      "<Response [200]>\n",
      "Index: 19, title: Red teaming language model detectors with language models. link: https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00639/119629\n",
      "<Response [200]>\n",
      "Index: 20, title: Paraphrase detection: Human vs. machine content. link: https://arxiv.org/abs/2303.13989\n",
      "<Response [200]>\n",
      "Index: 21, title: Detectllm: Leveraging log rank information for zero-shot detection of machine-generated text. link: https://arxiv.org/abs/2306.05540\n",
      "<Response [200]>\n",
      "Index: 22, title: Fast-detectgpt: Efficient zero-shot detection of machine-generated text via conditional probability curvature. link: https://arxiv.org/abs/2310.05130\n",
      "<Response [200]>\n",
      "Index: 23, title: Gpt-who: An information density-based machine-generated text detector. link: https://arxiv.org/abs/2310.06202\n",
      "<Response [200]>\n",
      "Index: 24, title: Cross-domain detection of GPT-2-generated technical text. link: https://aclanthology.org/2022.naacl-main.88/\n",
      "<Response [200]>\n",
      "Index: 25, title: Counter Turing Test CT\\^{} 2: AI-Generated Text Detection is Not as Easy as You May Think--Introducing AI Detectability Index. link: https://arxiv.org/abs/2310.05030\n",
      "<Response [200]>\n",
      "Index: 26, title: Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\\%* ChatGPT Quality. link: No results found\n",
      "<Response [200]>\n",
      "Index: 27, title: Bag of tricks for efficient text classification. link: https://arxiv.org/abs/1607.01759\n",
      "<Response [200]>\n",
      "Index: 28, title: MAGE: Machine-generated Text Detection in the Wild. link: https://ui.adsabs.harvard.edu/abs/2023arXiv230513242L/abstract\n",
      "<Response [200]>\n",
      "Index: 29, title: Origin tracing and detecting of llms. link: https://arxiv.org/abs/2304.14072\n",
      "<Response [200]>\n",
      "Index: 30, title: LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?. link: https://aclanthology.org/2024.findings-naacl.29/\n",
      "<Response [200]>\n",
      "Index: 31, title: Through the looking glass: Learning to attribute synthetic text generated by language models. link: https://aclanthology.org/2021.eacl-main.155/\n",
      "<Response [200]>\n",
      "Index: 32, title: Dna-gpt: Divergent n-gram analysis for training-free detection of gpt-generated text. link: https://arxiv.org/abs/2305.17359\n",
      "<Response [200]>\n",
      "Index: 33, title: Long-form analogies generated by chatGPT lack human-like psycholinguistic properties. link: https://arxiv.org/abs/2306.04537\n",
      "<Response [200]>\n",
      "Index: 34, title: Self-consuming generative models go mad. link: https://arxiv.org/abs/2307.01850\n",
      "<Response [200]>\n",
      "Index: 35, title: Machine-made media: Monitoring the mobilization of machine-generated articles on misinformation and mainstream news websites. link: https://ojs.aaai.org/index.php/ICWSM/article/view/31333\n",
      "<Response [200]>\n",
      "Index: 36, title: Machine-generated text: A comprehensive survey of threat models and detection methods. link: https://ieeexplore.ieee.org/abstract/document/10177704/\n",
      "<Response [200]>\n",
      "Index: 37, title: On the detectability of chatgpt content: benchmarking, methodology, and evaluation through the lens of academic writing. link: https://ui.adsabs.harvard.edu/abs/2023arXiv230605524L/abstract\n",
      "<Response [200]>\n",
      "Index: 38, title: ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models. link: https://arxiv.org/abs/2304.07666\n",
      "<Response [200]>\n",
      "Index: 39, title: Distinguishing Fact from Fiction: A Benchmark Dataset for Identifying Machine-Generated Scientific Papers in the LLM Era.. link: https://aclanthology.org/2023.trustnlp-1.17/\n",
      "<Response [200]>\n",
      "Index: 40, title: Overview of autextification at iberlef 2023: Detection and attribution of machine-generated text in multiple domains. link: https://arxiv.org/abs/2309.11285\n",
      "<Response [200]>\n",
      "Index: 41, title: On the Generalization of Training-based ChatGPT Detection Methods. link: https://arxiv.org/abs/2310.01307\n",
      "<Response [200]>\n",
      "Index: 42, title: M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection. link: https://arxiv.org/abs/2402.11175\n",
      "<Response [200]>\n",
      "Index: 43, title: Few-Shot Detection of Machine-Generated Text using Style Representations. link: https://arxiv.org/abs/2401.06712\n",
      "<Response [200]>\n",
      "Index: 44, title: HANSEN: human and AI spoken text benchmark for authorship analysis. link: https://arxiv.org/abs/2310.16746\n",
      "<Response [200]>\n",
      "Index: 45, title: A survey on llm-gernerated text detection: Necessity, methods, and future directions. link: https://arxiv.org/abs/2310.14724\n",
      "<Response [200]>\n",
      "Index: 46, title: Token prediction as implicit classification to identify LLM-generated text. link: https://arxiv.org/abs/2311.08723\n",
      "<Response [200]>\n",
      "Index: 47, title: Automatic Authorship Analysis in Human-AI Collaborative Writing. link: https://aclanthology.org/2024.lrec-main.165/\n",
      "<Response [200]>\n",
      "Index: 48, title: Effect of scale on catastrophic forgetting in neural networks. link: https://openreview.net/forum?id=GhVS8_yPeEa\n",
      "<Response [200]>\n",
      "Index: 49, title: Retrieval-augmented generation for knowledge-intensive nlp tasks. link: https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html\n",
      "<Response [200]>\n",
      "Index: 50, title: A survey on data selection for language models. link: https://arxiv.org/abs/2402.16827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract bibtex entries from a file\n",
    "def extract_bibtex_entries(file_path):\n",
    "    with open(file_path) as bibtex_file:\n",
    "        bib_database = bibtexparser.load(bibtex_file)\n",
    "    return bib_database.entries\n",
    "\n",
    "\n",
    "# Function to format authors\n",
    "def format_authors(authors):\n",
    "    author_list = authors.split(' and ')\n",
    "    formatted_authors = []\n",
    "    for author in author_list:\n",
    "        names = author.split(', ')\n",
    "        if len(names) == 2:\n",
    "            formatted_authors.append(f\"{names[1]} {names[0]}\")\n",
    "        else:\n",
    "            formatted_authors.append(names[0])\n",
    "    if len(formatted_authors) > 1:\n",
    "        return ', '.join(formatted_authors[:-1]) + ', and ' + formatted_authors[-1]\n",
    "    else:\n",
    "        return formatted_authors[0]\n",
    "\n",
    "\n",
    "# Function to generate markdown for the papers\n",
    "def generate_markdown(papers):\n",
    "    markdown = \"# Survey Paper List\\n\\n\"\n",
    "    for i, paper in enumerate(papers[290:]):\n",
    "        title = paper.get('title', 'No Title').strip('{}').replace('\\n', ' ')\n",
    "        authors = format_authors(paper.get('author', 'No Author'))\n",
    "        venue = paper.get('booktitle', paper.get('journal', 'No venue'))\n",
    "        year = paper.get('year', 'No Year')\n",
    "        # link = \"\"\n",
    "        link = get_paper_link(title, authors)\n",
    "        markdown += f\"- **{title}.** {authors}. *{venue}* ({year}) [[link]]({link})\\n\"\n",
    "        print(f\"Index: {i}, title: {title}. link: {link}\")\n",
    "    return markdown\n",
    "\n",
    "\n",
    "# Path to your .bib file\n",
    "bib_file_path = 'tmp.bib'\n",
    "\n",
    "# Extract bibtex entries\n",
    "papers = extract_bibtex_entries(bib_file_path)\n",
    "\n",
    "# Generate markdown\n",
    "markdown_content = generate_markdown(papers)\n",
    "\n",
    "with open('paper_list_rest.md', 'w') as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "len(papers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env24apr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
